name: Clean, Validate, and Upload Customer Data

on:
  workflow_dispatch: # Möjliggör manuell körning av workflow

jobs:
  clean-data:
    runs-on: ubuntu-latest

    steps:
      # Check out repository
      - name: Check out repository
        uses: actions/checkout@v3

      # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.9'

      # Install dependencies
      - name: Install dependencies
        run: pip install -r requirements.txt

      # Verify that input file exists
      - name: Verify input file
        run: |
          if [ ! -f "customer_data.xlsx" ]; then
            echo "Input file customer_data.xlsx does not exist!"
            exit 1
          fi

      # Run clean-up script
      - name: Run clean-up script
        run: python pipeline_scripts/clean_up.py

      # Verify cleaned_data files
      - name: Verify cleaned_data files
        run: ls cleaned_data/

      # Upload cleaned data artifact
      - name: Upload cleaned data artifact
        uses: actions/upload-artifact@v3
        with:
          name: cleaned-data
          path: cleaned_data/

      # Upload dirty data artifact
      - name: Upload dirty data artifact
        uses: actions/upload-artifact@v3
        with:
          name: validate-data
          path: validate_data/

  validate-and-convert:
    needs: clean-data
    runs-on: ubuntu-latest

    steps:
      # Check out repository
      - name: Check out repository
        uses: actions/checkout@v3

      # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.9'

      # Download cleaned data artifact
      - name: Download cleaned data artifact
        uses: actions/download-artifact@v3
        with:
          name: cleaned-data

      # Validate cleaned data
      - name: Validate cleaned data
        run: python pipeline_scripts/validate_data.py cleaned_data/clean_data.xlsx

      # Convert cleaned data to CSV
      - name: Convert cleaned data to CSV
        run: python pipeline_scripts/convert_to_csv.py cleaned_data/clean_data.xlsx cleaned_data/clean_data.csv

      # Upload converted CSV artifact
      - name: Upload CSV artifact
        uses: actions/upload-artifact@v3
        with:
          name: converted-data
          path: cleaned_data/clean_data.csv

  backup-and-upload:
    needs: validate-and-convert
    runs-on: ubuntu-latest

    steps:
      # Check out repository
      - name: Check out repository
        uses: actions/checkout@v3

      # Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.9'

      # Download converted data artifact
      - name: Download converted data artifact
        uses: actions/download-artifact@v3
        with:
          name: converted-data

      # Backup cleaned data to Azure Blob Storage
      - name: Backup cleaned data to Azure Blob Storage
        env:
          AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
          AZURE_STORAGE_KEY: ${{ secrets.AZURE_STORAGE_KEY }}
        run: |
          az storage blob upload \
            --account-name $AZURE_STORAGE_ACCOUNT \
            --account-key $AZURE_STORAGE_KEY \
            --container-name cleaned-data-backup \
            --file cleaned_data/clean_data.csv \
            --name clean_data_backup_$(date +'%Y%m%d%H%M%S').csv

      # Upload cleaned data to SQL database
      - name: Upload cleaned data to SQL database
        env:
          SQL_SERVER: ${{ secrets.SQL_SERVER }}
          SQL_DATABASE: ${{ secrets.SQL_DATABASE }}
          SQL_USER: ${{ secrets.SQL_USER }}
          SQL_PASSWORD: ${{ secrets.SQL_PASSWORD }}
        run: python pipeline_scripts/upload_to_sql.py cleaned_data/clean_data.xlsx
